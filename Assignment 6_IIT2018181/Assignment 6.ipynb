{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pda\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smsSpam = pda.read_csv('SMSSpamCollection',sep = '\\t', header = None, names=['Label','Messages'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smsSpam['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet,testingSet = tts(smsSpam,test_size = 0.3, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingSet['Messages'] = trainingSet['Messages'].str.replace('\\W', ' ')\n",
    "trainingSet['Messages'] = trainingSet['Messages'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingSet['Messages'] = testingSet['Messages'].str.replace('\\W', ' ')\n",
    "testingSet['Messages'] = testingSet['Messages'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865897\n",
       "spam    0.134103\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.866029\n",
       "spam    0.133971\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingSet['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet['Messages'] = trainingSet['Messages'].str.split()\n",
    "\n",
    "vocab = []\n",
    "for msg in trainingSet['Messages']:\n",
    "    for word in msg:\n",
    "        vocab.append(word)\n",
    "        \n",
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCountsPerMsg = {uniqueWord: [0]*len(trainingSet['Messages']) for uniqueWord in vocab}\n",
    "\n",
    "for idx, msg in enumerate(trainingSet['Messages']):\n",
    "    for word in msg:\n",
    "        wordCountsPerMsg[word][idx] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts = pda.DataFrame(wordCountsPerMsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSetFinal = pda.concat([trainingSet,wordCounts],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTINOMIAL NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamMsgs = trainingSetFinal[trainingSetFinal['Label']=='spam']\n",
    "hamMsgs = trainingSetFinal[trainingSetFinal['Label']=='ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pSpam = len(spamMsgs)/len(trainingSetFinal)\n",
    "pHam = len(hamMsgs)/len(trainingSetFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfWordsPerSpamMsgs = spamMsgs['Messages'].apply(len)\n",
    "noSpam = noOfWordsPerSpamMsgs.sum()\n",
    "noOfWordsPerHamMsgs = hamMsgs['Messages'].apply(len)\n",
    "noHam = noOfWordsPerHamMsgs.sum()\n",
    "noOfVocab = len(vocab)\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramSpam = {uniqueWord: 0 for uniqueWord in vocab}\n",
    "paramHam = {uniqueWord: 0 for uniqueWord in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocab:\n",
    "    noOfWordsGivenSpam = spamMsgs[word].sum()\n",
    "    probOfWordsGivenSpam = (noOfWordsGivenSpam + alpha)/(noSpam + alpha*noOfVocab)\n",
    "    paramSpam[word] = probOfWordsGivenSpam\n",
    "    noOfWordsGivenHam = hamMsgs[word].sum()\n",
    "    probOfWordsGivenHam = (noOfWordsGivenHam + alpha)/(noHam + alpha*noOfVocab)\n",
    "    paramHam[word] = probOfWordsGivenHam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyTestingSet(msg):\n",
    "    msg = re.sub('\\W', ' ', msg)\n",
    "    msg = msg.lower().split()\n",
    "    \n",
    "    probOfSpamGivenMsg = pSpam\n",
    "    probOfHamGivenMsg = pHam\n",
    "    \n",
    "    for word in msg:\n",
    "        if word in paramSpam:\n",
    "            probOfSpamGivenMsg *= paramSpam[word]\n",
    "            \n",
    "        if word in paramHam:\n",
    "            probOfHamGivenMsg *= paramHam[word]\n",
    "            \n",
    "        if probOfSpamGivenMsg > probOfHamGivenMsg:\n",
    "            return 'spam'\n",
    "        elif probOfHamGivenMsg > probOfSpamGivenMsg:\n",
    "            return 'ham'\n",
    "        else:\n",
    "            return 'need human classification'\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingSet['pred'] = testingSet['Messages'].apply(classifyTestingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right:  1448\n",
      "Wrong:  224\n",
      "Accuracy:  0.8660287081339713\n",
      "Error:  0.13397129186602874\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "tot = testingSet.shape[0]\n",
    "\n",
    "for row in testingSet.iterrows():\n",
    "    row = row[1]\n",
    "    if(row['Label']==row['pred']):\n",
    "        right +=1\n",
    "        \n",
    "print('Right: ', right)\n",
    "print('Wrong: ',tot-right)\n",
    "print('Accuracy: ',right/tot)\n",
    "print('Error: ', 1 -(right/tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Discriminant Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingY = trainingSetFinal['Label'].copy()\n",
    "trainingX = trainingSetFinal[trainingSetFinal.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingY = trainingY.to_numpy()\n",
    "trainingX = trainingX.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one = []\n",
    "X_zero = []\n",
    "\n",
    "for i in range(len(trainingY)):\n",
    "    if trainingY[i] == 'spam':\n",
    "        X_one.append(trainingX[i])\n",
    "    elif trainingY[i] == 'ham':\n",
    "        X_zero.append(trainingX[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi =  0.1341025641025641\n",
      "mu0 =  [[nan nan nan ... nan nan nan]]\n",
      "mu1 =  [[nan nan nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "phi = float(len(X_one)/(len(X_one)+len(X_zero)))\n",
    "mu0 = np.sum(np.matrix(X_zero),axis = 0)/len(X_zero)\n",
    "mu1 = np.sum(np.matrix(X_one),axis = 0)/len(X_one)\n",
    "print(\"Phi = \", phi)\n",
    "print(\"mu0 = \", mu0)\n",
    "print(\"mu1 = \", mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.zeros((trainingX.shape[1],trainingX.shape[1]))\n",
    "sigma0 = np.zeros((trainingX.shape[1],trainingX.shape[1]))\n",
    "sigma1 = np.zeros((trainingX.shape[1],trainingX.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trainingX)):\n",
    "    if(trainingY[i] == 'spam'):\n",
    "        sigma1 += np.dot(np.transpose(trainingX[i]-mu1),trainingX[i]-mu1)\n",
    "    elif trainingY[i]=='ham':\n",
    "        sigma0 += np.dot(np.transpose(trainingX[i]-mu0),trainingX[i]-mu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = (sigma1 + sigma0)/(len(X_one)+len(X_zero))\n",
    "sigma0 /= len(X_one)\n",
    "sigma1 /= len(X_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probFunction(x,mu,sigma):\n",
    "    m = len(x)\n",
    "    if m == mu.shape[1] and (m,m) == sigma.shape:\n",
    "        deter = np.linalg.det(sigma)\n",
    "        assert deter!=0, \"matrix cannot be singular\"\n",
    "        \n",
    "        temp = 1.0/(np.power((2*np.pi),float(m)/2)*np.power(deter,1.0/2))\n",
    "        xmu = np.matrix(x-mu)\n",
    "        siginv = inv(sigma)\n",
    "        res = np.power(np.e,-0.5*(np.dot(np.dot(xmu,siginv),np.transpose(xmu))))\n",
    "        return res*temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingSet['Messages'] = testingSet['Messages'].str.split()\n",
    "\n",
    "vocab = []\n",
    "for msg in testingSet['Messages']:\n",
    "    for word in msg:\n",
    "        vocab.append(word)\n",
    "        \n",
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCountsPerMsg = {uniqueWord: [0]*len(testingSet['Messages']) for uniqueWord in vocab}\n",
    "\n",
    "for idx, msg in enumerate(testingSet['Messages']):\n",
    "    for word in msg:\n",
    "        wordCountsPerMsg[word][idx] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts = pda.DataFrame(wordCountsPerMsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingSetFinal = pda.concat([testingSet,wordCounts],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingY = testingSetFinal['Label'].copy()\n",
    "testingX = testingSetFinal[testingSetFinal.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingY = testingY.to_numpy()\n",
    "testingX = testingX.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedY = []\n",
    "for x in testingX:\n",
    "    pa = probFunction(x,np.squeeze(mu0),np.matrix(sigma0))\n",
    "    pc = probFunction(x,np.squeeze(mu1),np.matrix(sigma1))\n",
    "    if (pa<pc):\n",
    "        predictedY.append('spam')\n",
    "    else:\n",
    "        predictedY.append('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(testingY)):\n",
    "    if(predictedY[i]==testingY[i]):\n",
    "        count = count + 1\n",
    "        \n",
    "accuracy = np.multiply(np.divide(count,len(testingY)),100)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIVARIATE BURNOULLI NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = {}\n",
    "ham = {}\n",
    "allWords = {}\n",
    "spamWordsCount = 0\n",
    "hamWordsCount = 0\n",
    "totalWords = 0\n",
    "spamCount = 0\n",
    "hamCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,msg in enumerate(trainingX):\n",
    "    if trainingY[i] == 'spam':\n",
    "        spamCount+=1\n",
    "        for word in msg:\n",
    "            if word in allWords:\n",
    "                allWords[word]=1\n",
    "            else:\n",
    "                allWords[word]=1\n",
    "            totalWords+=1\n",
    "            spamWordsCount+=1\n",
    "            if word in spam:\n",
    "                spam[word] = 1\n",
    "            else:\n",
    "                spam[word] = 1\n",
    "    elif trainingY[i] == 'ham':\n",
    "        hamCount+=1\n",
    "        for word in msg:\n",
    "            if word in allWords:\n",
    "                allWords[word]=1\n",
    "            else:\n",
    "                allWords[word]=1\n",
    "            totalWords+=1\n",
    "            hamWordsCount+=1\n",
    "            if word in ham:\n",
    "                ham[word] = 1\n",
    "            else:\n",
    "                ham[word] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "\n",
    "for word in allWords:\n",
    "    if word in spam:\n",
    "        prob = (1 + alpha)/(spamCount + alpha*len(allWords))\n",
    "        spam[word] = prob\n",
    "    else:\n",
    "        spam[word] = (alpha/(spamCount + alpha*len(allWords)))\n",
    "    if word in ham:\n",
    "        prob = (1 + alpha)/(hamCount + alpha*len(allWords))\n",
    "        ham[word] = prob\n",
    "    else:\n",
    "        ham[word] = (alpha/(hamCount + alpha*len(allWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyTestingSet(msg):\n",
    "    spamProb = spamCount/len(trainingSet)\n",
    "    hamProb = hamCount/len(trainingSet) \n",
    "    msg = re.sub('\\W', ' ', msg)\n",
    "    msg = msg.lower().split()\n",
    "    \n",
    "    probOfSpamGivenMsg = pSpam\n",
    "    probOfHamGivenMsg = pHam\n",
    "    \n",
    "    for word in msg:\n",
    "        if word in spam:\n",
    "            probOfSpamGivenMsg *= spam[word]\n",
    "        if word in ham:\n",
    "            probOfHamGivenMsg *= ham[word]\n",
    "            \n",
    "        if probOfSpamGivenMsg > probOfHamGivenMsg:\n",
    "            return 'spam'\n",
    "        elif probOfHamGivenMsg > probOfSpamGivenMsg:\n",
    "            return 'ham'\n",
    "        else:\n",
    "            return 'need human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingSet['pred'] = testingSet['Messages'].apply(classifyTestingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "tot = testingSet.shape[0]\n",
    "\n",
    "for row in testingSet.iterrows():\n",
    "    row = row[1]\n",
    "    if(row['Label']==row['pred']):\n",
    "        right +=1\n",
    "        \n",
    "print('Right: ', right)\n",
    "print('Wrong: ',tot-right)\n",
    "print('Accuracy: ',right/tot)\n",
    "print('Error: ', 1 -(right/tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Accuracy of Multinomial naive bayes is best in Spam Filtering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
